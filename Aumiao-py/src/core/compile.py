import base64
import hashlib
import json
import random
import xml.etree.ElementTree as ET  # noqa: S405
from pathlib import Path
from typing import Any, ClassVar

import requests
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.ciphers.aead import AESGCM


class BCMKNDecryptor:
	"""BCMKNæ–‡ä»¶è§£å¯†å™¨ - ç”¨äºNEKOç±»å‹ä½œå“"""

	def __init__(self) -> None:
		# å›ºå®šç›å€¼ - å¯¹åº”JavaScriptä¸­çš„M.j(31)
		self.default_salt = bytes(range(31))

	@staticmethod
	def reverse_string(s: str) -> str:
		"""å­—ç¬¦ä¸²åè½¬"""
		return s[::-1]

	@staticmethod
	def base64_to_bytes(base64_str: str) -> bytes:
		"""Base64è§£ç """
		try:
			return base64.b64decode(base64_str)
		except Exception as e:
			error_msg = f"Base64è§£ç é”™è¯¯: {e}"
			raise ValueError(error_msg) from e

	def generate_aes_key(self) -> bytes:
		"""ç”ŸæˆAESå¯†é’¥ - ä½¿ç”¨SHA-256ç®—æ³•"""
		digest = hashes.Hash(hashes.SHA256())
		digest.update(self.default_salt)
		return digest.finalize()

	@staticmethod
	def decrypt_aes_gcm(encrypted_data: bytes, key: bytes, iv: bytes) -> bytes:
		"""AES-GCMè§£å¯†"""
		try:
			aesgcm = AESGCM(key)
			return aesgcm.decrypt(iv, encrypted_data, None)
		except Exception as e:
			error_msg = f"AESè§£å¯†é”™è¯¯: {e}"
			raise ValueError(error_msg) from e

	def decrypt_data(self, encrypted_content: str) -> dict[str, Any]:
		"""è§£å¯†BCMKNæ•°æ®"""
		# æ­¥éª¤1: å­—ç¬¦ä¸²åè½¬
		reversed_data = self.reverse_string(encrypted_content)
		# æ­¥éª¤2: Base64è§£ç 
		decoded_data = self.base64_to_bytes(reversed_data)
		# æ­¥éª¤3: åˆ†ç¦»IVå’Œå¯†æ–‡ (IVä¸ºå‰12å­—èŠ‚)
		MIN_DATA_LENGTH = 13  # noqa: N806
		if len(decoded_data) < MIN_DATA_LENGTH:
			msg = "æ•°æ®å¤ªçŸ­,æ— æ³•åˆ†ç¦»IVå’Œå¯†æ–‡"
			raise ValueError(msg)
		iv = decoded_data[:12]
		ciphertext = decoded_data[12:]
		# æ­¥éª¤4: ç”ŸæˆAESå¯†é’¥
		key = self.generate_aes_key()
		# æ­¥éª¤5: AES-GCMè§£å¯†
		decrypted_bytes = self.decrypt_aes_gcm(ciphertext, key, iv)
		# æ¸…ç†å’Œä¿®å¤JSONæ•°æ®
		return self.clean_and_repair_json(decrypted_bytes)

	@staticmethod
	def find_valid_json_end(text: str) -> int:
		"""æ‰¾åˆ°æœ‰æ•ˆçš„JSONç»“æŸä½ç½®"""
		stack: list[str] = []
		in_string = False
		escape = False
		for i, char in enumerate(text):
			if escape:
				escape = False
				continue
			if char == "\\":
				escape = True
				continue
			if char == '"':
				in_string = not in_string
				continue
			if in_string:
				continue
			if char in "{[":
				stack.append(char)
			elif char in "}]":
				if not stack:
					return i
				opening = stack.pop()
				if (opening == "{" and char != "}") or (opening == "[" and char != "]"):
					return i
				if not stack:
					return i + 1
		if stack:
			for i in range(len(text) - 1, -1, -1):
				if text[i] in "}]":
					try:
						json.loads(text[: i + 1])
						return i + 1
					except json.JSONDecodeError:
						continue
		return len(text)

	def clean_and_repair_json(self, raw_bytes: bytes) -> dict[str, Any]:
		"""æ¸…ç†å’Œä¿®å¤JSONæ•°æ®"""
		text_content = raw_bytes.decode("utf-8", errors="ignore")
		# æŸ¥æ‰¾æœ‰æ•ˆçš„JSONç»“æŸä½ç½®
		valid_end = self.find_valid_json_end(text_content)
		if valid_end < len(text_content):
			text_content = text_content[:valid_end]
		# å°è¯•è§£æJSON
		try:
			return json.loads(text_content)
		except json.JSONDecodeError:
			# å°è¯•ä¿®å¤å¸¸è§çš„JSONé—®é¢˜
			repaired_content = self.repair_json(text_content)
			try:
				return json.loads(repaired_content)
			except json.JSONDecodeError as decode_error:
				error_msg = "JSONè§£æå¤±è´¥,æ•°æ®å¯èƒ½å·²æŸå"
				raise ValueError(error_msg) from decode_error

	@staticmethod
	def repair_json(text: str) -> str:
		"""å°è¯•ä¿®å¤JSONæ•°æ®"""
		# ç§»é™¤æœ«å°¾çš„é€—å·
		text = text.rstrip()
		while text and text[-1] in ", \t\n\r":
			text = text[:-1]
		# ç¡®ä¿ä»¥ } æˆ– ] ç»“æŸ
		if not text.endswith("}") and not text.endswith("]"):
			last_brace = text.rfind("}")
			last_bracket = text.rfind("]")
			last_valid = max(last_brace, last_bracket)
			if last_valid > 0:
				text = text[: last_valid + 1]
		return text


class Network:
	"""ç½‘ç»œè¯·æ±‚å·¥å…·ç±»"""

	@staticmethod
	def fetch_json(url: str) -> dict[str, Any]:
		"""è·å–JSONæ•°æ®"""
		response = requests.get(url, timeout=30)
		response.raise_for_status()
		return response.json()

	@staticmethod
	def fetch_binary(url: str) -> bytes:
		"""è·å–äºŒè¿›åˆ¶æ•°æ®"""
		response = requests.get(url, timeout=30)
		response.raise_for_status()
		return response.content

	@staticmethod
	def fetch_text(url: str) -> str:
		"""è·å–æ–‡æœ¬æ•°æ®"""
		response = requests.get(url, timeout=30)
		response.raise_for_status()
		return response.text


class Crypto:
	"""åŠ å¯†å“ˆå¸Œå·¥å…·ç±»"""

	@staticmethod
	def sha256(data: str | bytes) -> str:
		"""è®¡ç®—SHA256å“ˆå¸Œ"""
		if isinstance(data, str):
			data = data.encode()
		return hashlib.sha256(data).hexdigest()


class WorkInfo:
	"""ä½œå“ä¿¡æ¯å®¹å™¨"""

	def __init__(self, data: dict[str, Any]) -> None:
		self.id = data["id"]
		self.name = data.get("work_name", data.get("name", "æœªçŸ¥ä½œå“"))
		self.type = data.get("type", "NEMO")
		self.version = data.get("bcm_version", "0.16.2")
		self.user_id = data.get("user_id", 0)
		self.preview_url = data.get("preview", "")
		self.source_urls = data.get("source_urls", data.get("work_urls", []))

	@property
	def file_extension(self) -> str:
		"""æ ¹æ®ä½œå“ç±»å‹è¿”å›æ–‡ä»¶æ‰©å±•å"""
		extensions = {
			"KITTEN2": ".bcm",
			"KITTEN3": ".bcm",
			"KITTEN4": ".bcm4",
			"COCO": ".json",
			"NEMO": "",
			"NEKO": ".json",  # NEKOç±»å‹ä½¿ç”¨JSONæ ¼å¼
		}
		return extensions.get(self.type, ".json")

	@property
	def is_nemo(self) -> bool:
		"""æ˜¯å¦ä¸ºNemoä½œå“"""
		return self.type == "NEMO"

	@property
	def is_neko(self) -> bool:
		"""æ˜¯å¦ä¸ºNEKOä½œå“"""
		return self.type == "NEKO"


class FileHelper:
	"""æ–‡ä»¶æ“ä½œå·¥å…·ç±»"""

	@staticmethod
	def safe_filename(name: str, work_id: int, extension: str = "") -> str:
		"""ç”Ÿæˆå®‰å…¨æ–‡ä»¶å"""
		safe_name = "".join(c for c in name if c.isalnum() or c in {" ", "-", "_"}).strip()
		if not safe_name:
			safe_name = f"work_{work_id}"
		if extension and not extension.startswith("."):
			extension = f".{extension}"
		return f"{safe_name}_{work_id}{extension}"

	@staticmethod
	def ensure_dir(path: str | Path) -> None:
		"""ç¡®ä¿ç›®å½•å­˜åœ¨"""
		Path(path).mkdir(parents=True, exist_ok=True)

	@staticmethod
	def write_json(path: str | Path, data: Any) -> None:  # noqa: ANN401
		"""å†™å…¥JSONæ–‡ä»¶"""
		with Path(path).open("w", encoding="utf-8") as f:
			json.dump(data, f, ensure_ascii=False, indent=2)

	@staticmethod
	def write_binary(path: str | Path, data: bytes) -> None:
		"""å†™å…¥äºŒè¿›åˆ¶æ–‡ä»¶"""
		with Path(path).open("wb") as f:
			f.write(data)


class ShadowBuilder:
	"""é˜´å½±ç§¯æœ¨æ„å»ºå™¨"""

	SHADOW_TYPES: ClassVar[set[str]] = {
		"broadcast_input",
		"controller_shadow",
		"default_value",
		"get_audios",
		"get_current_costume",
		"get_current_scene",
		"get_sensing_current_scene",
		"get_whole_audios",
		"lists_get",
		"logic_empty",
		"math_number",
		"text",
	}
	FIELD_CONFIG: ClassVar[dict[str, dict[str, str]]] = {
		"broadcast_input": {"name": "MESSAGE", "text": "Hi"},
		"controller_shadow": {"name": "NUM", "text": "0", "constraints": "-Infinity,Infinity,0,false"},
		"default_value": {"name": "TEXT", "text": "0", "has_been_edited": "false"},
		"get_audios": {"name": "sound_id", "text": "?"},
		"get_current_costume": {"name": "style_id", "text": ""},
		"get_current_scene": {"name": "scene", "text": ""},
		"get_sensing_current_scene": {"name": "scene", "text": ""},
		"get_whole_audios": {"name": "sound_id", "text": "all"},
		"lists_get": {"name": "VAR", "text": "?"},
		"math_number": {"name": "NUM", "text": "0", "constraints": "-Infinity,Infinity,0,", "allow_text": "true"},
		"text": {"name": "TEXT", "text": ""},
	}

	@staticmethod
	def generate_id(length: int = 20) -> str:
		"""ç”ŸæˆéšæœºID"""
		chars = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"
		return "".join(random.choice(chars) for _ in range(length))

	def create(self, shadow_type: str, block_id: str | None = None, text: str | None = None) -> str:
		"""åˆ›å»ºé˜´å½±ç§¯æœ¨"""
		if shadow_type == "logic_empty":
			block_id = block_id or self.generate_id()
			return f'<empty type="logic_empty" id="{block_id}" visible="visible" editable="false"></empty>'
		config = self.FIELD_CONFIG.get(shadow_type, {})
		block_id = block_id or self.generate_id()
		display_text = text or config.get("text", "")
		shadow = ET.Element("shadow")
		shadow.set("type", shadow_type)
		shadow.set("id", block_id)
		shadow.set("visible", "visible")
		shadow.set("editable", "true")
		field = ET.SubElement(shadow, "field")
		field.set("name", config["name"])
		field.text = str(display_text)
		for attr in ["constraints", "allow_text", "has_been_edited"]:
			if attr in config:
				field.set(attr, config[attr])
		return ET.tostring(shadow, encoding="unicode")


class BaseDecompiler:
	"""åç¼–è¯‘å™¨åŸºç±»"""

	def __init__(self, work_info: WorkInfo) -> None:
		self.work_info = work_info
		self.shadow_builder = ShadowBuilder()

	def decompile(self) -> dict[str, Any] | str:
		"""åç¼–è¯‘ä½œå“ - å­ç±»å¿…é¡»å®ç°"""
		raise NotImplementedError


class NekoDecompiler(BaseDecompiler):
	"""NEKOä½œå“åç¼–è¯‘å™¨"""

	def decompile(self) -> dict[str, Any]:
		"""åç¼–è¯‘NEKOä½œå“"""
		print(f"ğŸ”“ å¼€å§‹è§£å¯†NEKOä½œå“: {self.work_info.id}")
		# è·å–ä½œå“è¯¦æƒ…ä»¥è·å–åŠ å¯†æ–‡ä»¶URL
		detail_url = f"https://api-creation.codemao.cn/neko/community/player/published-work-detail/{self.work_info.id}"
		try:
			detail_data = Network.fetch_json(detail_url)
			encrypted_url = detail_data["source_urls"][0]
			print(f"ğŸ“¥ è·å–åŠ å¯†æ–‡ä»¶URL: {encrypted_url}")
		except Exception as e:
			error_msg = "è·å–ä½œå“è¯¦æƒ…å¤±è´¥"
			raise ValueError(error_msg) from e
		# ä¸‹è½½åŠ å¯†æ–‡ä»¶
		try:
			encrypted_content = Network.fetch_text(encrypted_url)
			print(f"ğŸ“Š ä¸‹è½½åŠ å¯†æ•°æ®å®Œæˆ,é•¿åº¦: {len(encrypted_content)} å­—ç¬¦")
		except Exception as e:
			error_msg = "ä¸‹è½½åŠ å¯†æ–‡ä»¶å¤±è´¥"
			raise ValueError(error_msg) from e
		# è§£å¯†æ–‡ä»¶
		decryptor = BCMKNDecryptor()
		try:
			decrypted_data = decryptor.decrypt_data(encrypted_content)
			print("âœ… NEKOä½œå“è§£å¯†æˆåŠŸ!")
			return decrypted_data  # noqa: TRY300
		except Exception as e:
			error_msg = "è§£å¯†å¤±è´¥"
			raise ValueError(error_msg) from e


class NemoDecompiler(BaseDecompiler):
	"""Nemoä½œå“åç¼–è¯‘å™¨"""

	def decompile(self) -> str:
		"""åç¼–è¯‘Nemoä½œå“ä¸ºæ–‡ä»¶å¤¹ç»“æ„"""
		work_id = self.work_info.id
		work_dir = Path(f"nemo_work_{work_id}")
		FileHelper.ensure_dir(work_dir)
		source_info = Network.fetch_json(f"https://api.codemao.cn/creation-tools/v1/works/{work_id}/source/public")
		bcm_data = Network.fetch_json(source_info["work_urls"][0])
		dirs = self._create_directories(work_dir, work_id)
		self._save_core_files(dirs, work_id, bcm_data, source_info)
		self._download_resources(dirs, bcm_data)
		return str(work_dir)

	@staticmethod
	def _create_directories(base_dir: Path, work_id: int) -> dict[str, Path]:
		"""åˆ›å»ºç›®å½•ç»“æ„"""
		dirs = {
			"material": base_dir / "user_material",
			"works": base_dir / "user_works" / str(work_id),
			"record": base_dir / "user_works" / str(work_id) / "record",
		}
		for path in dirs.values():
			FileHelper.ensure_dir(path)
		return dirs

	def _save_core_files(self, dirs: dict[str, Path], work_id: int, bcm_data: dict[str, Any], source_info: dict[str, Any]) -> None:
		"""ä¿å­˜æ ¸å¿ƒæ–‡ä»¶"""
		bcm_path = dirs["works"] / f"{work_id}.bcm"
		FileHelper.write_json(bcm_path, bcm_data)
		user_images = self._build_user_images(bcm_data)
		user_img_path = dirs["works"] / f"{work_id}.userimg"
		FileHelper.write_json(user_img_path, user_images)
		meta_data = self._build_metadata(work_id, source_info)
		meta_path = dirs["works"] / f"{work_id}.meta"
		FileHelper.write_json(meta_path, meta_data)
		if source_info.get("preview"):
			try:
				cover_data = Network.fetch_binary(source_info["preview"])
				cover_path = dirs["works"] / f"{work_id}.cover"
				FileHelper.write_binary(cover_path, cover_data)
			except Exception as e:
				print(f"å°é¢ä¸‹è½½å¤±è´¥: {e}")

	@staticmethod
	def _build_user_images(bcm_data: dict[str, Any]) -> dict[str, Any]:
		"""æ„å»ºç”¨æˆ·å›¾ç‰‡é…ç½®"""
		user_images = {"user_img_dict": {}}
		styles = bcm_data.get("styles", {}).get("styles_dict", {})
		for style_id, style_data in styles.items():
			image_url = style_data.get("url")
			if image_url:
				user_images["user_img_dict"][style_id] = {"id": style_id, "path": f"user_material/{Crypto.sha256(image_url)}.webp"}
		return user_images

	@staticmethod
	def _build_metadata(work_id: int, source_info: dict[str, Any]) -> dict[str, Any]:
		"""æ„å»ºå…ƒæ•°æ®"""
		return {
			"bcm_count": {
				"block_cnt_without_invisible": 0.0,
				"block_cnt": 0.0,
				"entity_cnt": 1.0,
			},
			"bcm_name": source_info["name"],
			"bcm_url": source_info["work_urls"][0],
			"bcm_version": source_info["bcm_version"],
			"download_fail": False,
			"extra_data": {},
			"have_published_status": False,
			"have_remote_resources": False,
			"is_landscape": False,
			"is_micro_bit": False,
			"is_valid": False,
			"mcloud_variable": [],
			"publish_preview": source_info["preview"],
			"publish_status": 0,
			"review_state": 0,
			"template_id": 0,
			"term_id": 0,
			"type": 0,
			"upload_status": {
				"work_id": work_id,
				"have_uploaded": 2,
			},
		}

	@staticmethod
	def _download_resources(dirs: dict[str, Path], bcm_data: dict[str, Any]) -> None:
		"""ä¸‹è½½èµ„æºæ–‡ä»¶"""
		styles = bcm_data.get("styles", {}).get("styles_dict", {})
		for style_data in styles.values():
			image_url = style_data.get("url")
			if image_url:
				try:
					image_data = Network.fetch_binary(image_url)
					file_name = f"{Crypto.sha256(image_url)}.webp"
					file_path = dirs["material"] / file_name
					FileHelper.write_binary(file_path, image_data)
				except Exception as e:
					print(f"èµ„æºä¸‹è½½å¤±è´¥ {image_url}: {e}")


class KittenDecompiler(BaseDecompiler):
	"""Kittenä½œå“åç¼–è¯‘å™¨"""

	def __init__(self, work_info: WorkInfo) -> None:
		super().__init__(work_info)
		self.functions: dict[str, Any] = {}

	def decompile(self) -> dict[str, Any]:
		"""åç¼–è¯‘Kittenä½œå“"""
		compiled_data = self._fetch_compiled_data()
		work = compiled_data.copy()
		self._decompile_actors(work)
		self._update_work_info(work)
		self._clean_work_data(work)
		return work

	def _fetch_compiled_data(self) -> dict[str, Any]:
		"""è·å–ç¼–è¯‘æ•°æ®"""
		work_id = self.work_info.id
		if self.work_info.type in {"KITTEN2", "KITTEN3", "KITTEN4"}:
			url = f"https://api-creation.codemao.cn/kitten/r2/work/player/load/{work_id}"
			compiled_url = Network.fetch_json(url)["source_urls"][0]
		else:
			compiled_url = self.work_info.source_urls[0]
		return Network.fetch_json(compiled_url)

	def _decompile_actors(self, work: dict[str, Any]) -> None:
		"""åç¼–è¯‘æ‰€æœ‰è§’è‰²"""
		actors = []
		for actor_data in work["compile_result"]:
			actor_info = self._get_actor_info(work, actor_data["id"])
			actor = ActorProcessor(self, actor_info, actor_data)
			actors.append(actor)
		for actor in actors:
			actor.prepare()
		for actor in actors:
			actor.process()

	@staticmethod
	def _get_actor_info(work: dict[str, Any], actor_id: str) -> dict[str, Any]:
		"""è·å–è§’è‰²ä¿¡æ¯"""
		theatre = work["theatre"]
		if actor_id in theatre["actors"]:
			return theatre["actors"][actor_id]
		if actor_id in theatre["scenes"]:
			return theatre["scenes"][actor_id]
		print(f"è­¦å‘Š: è§’è‰²ID {actor_id} åœ¨actorså’Œscenesä¸­å‡æœªæ‰¾åˆ°,ä½¿ç”¨ç©ºè§’è‰²ä¿¡æ¯")
		return {
			"id": actor_id,
			"name": f"æœªçŸ¥è§’è‰²_{actor_id[:8]}",
			"type": "sprite",
			"visible": True,
			"x": 0,
			"y": 0,
			"size": 100,
			"direction": 90,
			"draggable": False,
			"rotation_style": "all around",
		}

	def _update_work_info(self, work: dict[str, Any]) -> None:
		"""æ›´æ–°ä½œå“ä¿¡æ¯"""
		toolbox_categories = [
			"action",
			"advanced",
			"ai",
			"ai_game",
			"ai_lab",
			"appearance",
			"arduino",
			"audio",
			"camera",
			"cloud_list",
			"cloud_variable",
			"cognitive",
			"control",
			"data",
			"event",
			"micro_bit",
			"midi_music",
			"mobile_control",
			"operator",
			"pen",
			"physic",
			"physics2",
			"procedure",
			"sensing",
			"video",
			"wee_make",
			"wood",
		]
		work.update(
			{
				"hidden_toolbox": {"toolbox": [], "blocks": []},
				"work_source_label": 0,
				"sample_id": "",
				"project_name": self.work_info.name,
				"toolbox_order": toolbox_categories,
				"last_toolbox_order": toolbox_categories,
			}
		)

	@staticmethod
	def _clean_work_data(work: dict[str, Any]) -> None:
		"""æ¸…ç†ä½œå“æ•°æ®"""
		for key in ["compile_result", "preview", "author_nickname"]:
			work.pop(key, None)


class ActorProcessor:
	"""è§’è‰²å¤„ç†å™¨"""

	def __init__(self, decompiler: KittenDecompiler, actor_info: dict[str, Any], compiled_data: dict[str, Any]) -> None:
		self.decompiler = decompiler
		self.actor_info = actor_info
		self.compiled_data = compiled_data
		self.blocks: dict[str, Any] = {}
		self.connections: dict[str, Any] = {}

	def prepare(self) -> None:
		"""å‡†å¤‡é˜¶æ®µ"""
		self.actor_info["block_data_json"] = {"blocks": self.blocks, "connections": self.connections, "comments": {}}

	def process(self) -> None:
		"""å¤„ç†è§’è‰²"""
		for func_name, func_data in self.compiled_data["procedures"].items():
			processor = FunctionProcessor(func_data, self)
			self.decompiler.functions[func_name] = processor.process()
		for block_data in self.compiled_data["compiled_block_map"].values():
			self.process_block(block_data)

	def process_block(self, compiled: dict[str, Any]) -> dict[str, Any]:
		"""å¤„ç†å•ä¸ªç§¯æœ¨"""
		block_type = compiled["type"]
		if block_type == "controls_if":
			processor = IfBlockProcessor(compiled, self)
		elif block_type == "text_join":
			processor = TextJoinProcessor(compiled, self)
		elif block_type.startswith("procedures_2_def"):
			processor = FunctionProcessor(compiled, self)
		elif block_type.startswith("procedures_2_call"):
			processor = FunctionCallProcessor(compiled, self)
		else:
			processor = BlockProcessor(compiled, self)
		return processor.process()


class BlockProcessor:
	"""ç§¯æœ¨å¤„ç†å™¨åŸºç±»"""

	def __init__(self, compiled: dict[str, Any], actor: ActorProcessor) -> None:
		self.compiled = compiled
		self.actor = actor
		self.block: dict[str, Any] = {}
		self.connection: dict[str, Any] = {}
		self.shadows: dict[str, Any] = {}
		self.fields: dict[str, Any] = {}

	def process(self) -> dict[str, Any]:
		"""å¤„ç†ç§¯æœ¨"""
		self._setup_basic_info()
		self._process_next()
		self._process_children()
		self._process_conditions()
		self._process_params()
		return self.block

	def _setup_basic_info(self) -> None:
		"""è®¾ç½®åŸºç¡€ä¿¡æ¯"""
		block_id = self.compiled["id"]
		block_type = self.compiled["type"]
		shadow_types = self.actor.decompiler.shadow_builder.SHADOW_TYPES
		self.block.update(
			{
				"id": block_id,
				"type": block_type,
				"location": [0, 0],
				"is_shadow": block_type in shadow_types,
				"collapsed": False,
				"disabled": False,
				"deletable": True,
				"movable": True,
				"editable": True,
				"visible": "visible",
				"shadows": self.shadows,
				"fields": self.fields,
				"field_constraints": {},
				"field_extra_attr": {},
				"comment": None,
				"mutation": "",
				"is_output": (block_type in shadow_types or block_type in {"logic_boolean", "procedures_2_stable_parameter"}),
				"parent_id": None,
			}
		)
		self.actor.connections[block_id] = self.connection
		self.actor.blocks[block_id] = self.block

	def _process_next(self) -> None:
		"""å¤„ç†ä¸‹ä¸€ä¸ªç§¯æœ¨"""
		if "next_block" in self.compiled:
			next_block = self.actor.process_block(self.compiled["next_block"])
			next_block["parent_id"] = self.block["id"]
			self.connection[next_block["id"]] = {"type": "next"}

	def _process_children(self) -> None:
		"""å¤„ç†å­ç§¯æœ¨"""
		if "child_block" in self.compiled:
			for i, child in enumerate(self.compiled["child_block"]):
				if child is not None:
					child_block = self.actor.process_block(child)
					child_block["parent_id"] = self.block["id"]
					input_name = self._get_child_input_name(i)
					self.connection[child_block["id"]] = {"type": "input", "input_type": "statement", "input_name": input_name}
					self.shadows[input_name] = ""

	def _process_conditions(self) -> None:
		"""å¤„ç†æ¡ä»¶ç§¯æœ¨"""
		if "conditions" in self.compiled:
			for i, condition in enumerate(self.compiled["conditions"]):
				condition_block = self.actor.process_block(condition)
				condition_block["parent_id"] = self.block["id"]
				input_name = f"IF{i}"
				if condition_block["type"] != "logic_empty":
					self.connection[condition_block["id"]] = {"type": "input", "input_type": "value", "input_name": input_name}
				shadow = self.actor.decompiler.shadow_builder.create("logic_empty", condition_block["id"])
				self.shadows[input_name] = shadow

	def _process_params(self) -> None:
		"""å¤„ç†å‚æ•°"""
		for name, value in self.compiled["params"].items():
			if isinstance(value, dict):
				param_block = self.actor.process_block(value)
				param_block["parent_id"] = self.block["id"]
				param_type = param_block["type"]
				if param_type in self.actor.decompiler.shadow_builder.SHADOW_TYPES:
					field_values = list(param_block["fields"].values())
					field_value = field_values[0] if field_values else ""
					shadow = self.actor.decompiler.shadow_builder.create(param_type, param_block["id"], field_value)
				else:
					shadow_type = "logic_empty" if name in {"condition", "BOOL"} else "math_number"
					shadow = self.actor.decompiler.shadow_builder.create(shadow_type)
				self.shadows[name] = shadow
				self.connection[param_block["id"]] = {"type": "input", "input_type": "value", "input_name": name}
			else:
				self.fields[name] = value

	@staticmethod
	def _get_child_input_name(_index: int) -> str:
		return "DO"


class IfBlockProcessor(BlockProcessor):
	"""æ¡ä»¶ç§¯æœ¨å¤„ç†å™¨"""

	MIN_CONDITIONS_FOR_ELSE = 2

	def process(self) -> dict[str, Any]:
		block = super().process()
		children = self.compiled["child_block"]
		if len(children) == self.MIN_CONDITIONS_FOR_ELSE and children[-1] is None:
			self.shadows["EXTRA_ADD_ELSE"] = ""
		else:
			condition_count = len(self.compiled["conditions"])
			self.block["mutation"] = f'<mutation elseif="{condition_count - 1}" else="1"></mutation>'
			self.shadows["ELSE_TEXT"] = ""
		return block

	def _get_child_input_name(self, index: int) -> str:  # pyright: ignore[reportIncompatibleMethodOverride]
		conditions_count = len(self.compiled["conditions"])
		return f"DO{index}" if index < conditions_count else "ELSE"


class TextJoinProcessor(BlockProcessor):
	"""æ–‡æœ¬è¿æ¥ç§¯æœ¨å¤„ç†å™¨"""

	def process(self) -> dict[str, Any]:
		block = super().process()
		param_count = len(self.compiled["params"])
		self.block["mutation"] = f'<mutation items="{param_count}"></mutation>'
		return block


class FunctionProcessor(BlockProcessor):
	"""å‡½æ•°å®šä¹‰å¤„ç†å™¨"""

	def process(self) -> dict[str, Any]:
		self._setup_basic_info()
		self._process_children()
		self.shadows["PROCEDURES_2_DEFNORETURN_DEFINE"] = ""
		self.shadows["PROCEDURES_2_DEFNORETURN_MUTATOR"] = ""
		self.fields["NAME"] = self.compiled["procedure_name"]
		mutation = ET.Element("mutation")
		for i, (param_name, _) in enumerate(self.compiled["params"].items()):
			input_name = f"PARAMS{i}"
			arg = ET.SubElement(mutation, "arg")
			arg.set("name", input_name)
			shadow = self.actor.decompiler.shadow_builder.create("math_number")
			self.shadows[input_name] = shadow
			param_block = self.actor.process_block(
				{
					"id": ShadowBuilder.generate_id(),
					"kind": "domain_block",
					"type": "procedures_2_stable_parameter",
					"params": {"param_name": param_name, "param_default_value": ""},
				}
			)
			param_block["parent_id"] = self.block["id"]
			self.connection[param_block["id"]] = {"type": "input", "input_type": "value", "input_name": input_name}
		self.block["mutation"] = ET.tostring(mutation, encoding="unicode")
		return self.block

	@staticmethod
	def _get_child_input_name(_index: int) -> str:
		return "STACK"


class FunctionCallProcessor(BlockProcessor):
	"""å‡½æ•°è°ƒç”¨å¤„ç†å™¨"""

	def process(self) -> dict[str, Any]:
		self._setup_basic_info()
		self._process_next()
		func_name = self.compiled["procedure_name"]
		functions = self.actor.decompiler.functions
		try:
			func_id = functions[func_name]["id"]
		except KeyError:
			func_id = ShadowBuilder.generate_id()
			self.block["disabled"] = True
		self.shadows["NAME"] = ""
		self.fields["NAME"] = func_name
		mutation = ET.Element("mutation")
		mutation.set("name", func_name)
		mutation.set("def_id", func_id)
		for i, (param_name, param_value) in enumerate(self.compiled["params"].items()):
			param_block = self.actor.process_block(param_value)
			shadow = self.actor.decompiler.shadow_builder.create("default_value", param_block["id"])
			self.shadows[f"ARG{i}"] = shadow
			param_elem = ET.SubElement(mutation, "procedures_2_parameter_shadow")
			param_elem.set("name", param_name)
			param_elem.set("value", "0")
			self.connection[param_block["id"]] = {"type": "input", "input_type": "value", "input_name": f"ARG{i}"}
		self.block["mutation"] = ET.tostring(mutation, encoding="unicode")
		return self.block


class CocoDecompiler(BaseDecompiler):
	"""CoCoä½œå“åç¼–è¯‘å™¨"""

	def decompile(self) -> dict[str, Any]:
		"""åç¼–è¯‘CoCoä½œå“"""
		compiled_data = self._fetch_compiled_data()
		work = compiled_data.copy()
		self._reorganize_data(work)
		self._clean_data(work)
		return work

	def _fetch_compiled_data(self) -> dict[str, Any]:
		"""è·å–ç¼–è¯‘æ•°æ®"""
		work_id = self.work_info.id
		url = f"https://api-creation.codemao.cn/coconut/web/work/{work_id}/load"
		compiled_url = Network.fetch_json(url)["data"]["bcmc_url"]
		return Network.fetch_json(compiled_url)

	def _reorganize_data(self, work: dict[str, Any]) -> None:
		"""é‡ç»„æ•°æ®"""
		work["authorId"] = self.work_info.user_id
		work["title"] = self.work_info.name
		work["screens"] = {}
		work["screenIds"] = []
		for screen in work["screenList"]:
			screen_id = screen["id"]
			screen["snapshot"] = ""
			work["screens"][screen_id] = screen
			work["screenIds"].append(screen_id)
			screen.update(
				{
					"primitiveVariables": [],
					"arrayVariables": [],
					"objectVariables": [],
					"broadcasts": ["Hi"],
					"widgets": {},
				}
			)
			for widget_id in screen["widgetIds"] + screen["invisibleWidgetIds"]:
				screen["widgets"][widget_id] = work["widgetMap"][widget_id]
				del work["widgetMap"][widget_id]
		work["blockly"] = {}
		for screen_id, blocks in work["blockJsonMap"].items():
			work["blockly"][screen_id] = {"screenId": screen_id, "workspaceJson": blocks, "workspaceOffset": {"x": 0, "y": 0}}
		self._process_resources(work)
		self._process_variables(work)
		work.update(
			{
				"globalWidgets": work["widgetMap"],
				"globalWidgetIds": list(work["widgetMap"].keys()),
				"sourceTag": 1,
				"sourceId": "",
			}
		)

	@staticmethod
	def _process_resources(work: dict[str, Any]) -> None:
		"""å¤„ç†èµ„æºæ–‡ä»¶"""
		resource_maps = ["imageFileMap", "soundFileMap", "iconFileMap", "fontFileMap"]
		for map_name in resource_maps:
			if map_name in work:
				list_name = map_name.replace("Map", "List")
				work[list_name] = list(work[map_name].values())

	@staticmethod
	def _process_variables(work: dict[str, Any]) -> None:
		"""å¤„ç†å˜é‡"""
		counters = {"var": 0, "list": 0, "dict": 0}
		variable_lists = {
			"globalVariableList": [],
			"globalArrayList": [],
			"globalObjectList": [],
		}
		for var_id, value in work["variableMap"].items():
			if isinstance(value, list):
				counters["list"] += 1
				variable_lists["globalArrayList"].append({"id": var_id, "name": f"åˆ—è¡¨{counters['list']}", "defaultValue": value, "value": value})
			elif isinstance(value, dict):
				counters["dict"] += 1
				variable_lists["globalObjectList"].append({"id": var_id, "name": f"å­—å…¸{counters['dict']}", "defaultValue": value, "value": value})
			else:
				counters["var"] += 1
				variable_lists["globalVariableList"].append({"id": var_id, "name": f"å˜é‡{counters['var']}", "defaultValue": value, "value": value})
		work.update(variable_lists)

	@staticmethod
	def _clean_data(work: dict[str, Any]) -> None:
		"""æ¸…ç†æ•°æ®"""
		remove_keys = [
			"apiToken",
			"blockCode",
			"blockJsonMap",
			"fontFileMap",
			"gridMap",
			"iconFileMap",
			"id",
			"imageFileMap",
			"initialScreenId",
			"screenList",
			"soundFileMap",
			"variableMap",
			"widgetMap",
		]
		for key in remove_keys:
			work.pop(key, None)


class Decompiler:
	"""åç¼–è¯‘å™¨ä¸»ç±»"""

	def __init__(self) -> None:
		self.decompilers = {
			"NEMO": NemoDecompiler,
			"KITTEN2": KittenDecompiler,
			"KITTEN3": KittenDecompiler,
			"KITTEN4": KittenDecompiler,
			"COCO": CocoDecompiler,
			"NEKO": NekoDecompiler,  # æ·»åŠ NEKOæ”¯æŒ
		}

	def decompile(self, work_id: int, output_dir: str = "decompiled") -> str:
		"""
		åç¼–è¯‘ä½œå“
		Args:
			work_id: ä½œå“ID
			output_dir: è¾“å‡ºç›®å½•
		Returns:
			ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
		"""
		print(f"å¼€å§‹åç¼–è¯‘ä½œå“ {work_id}...")
		raw_info = Network.fetch_json(f"https://api.codemao.cn/creation-tools/v1/works/{work_id}")
		work_info = WorkInfo(raw_info)
		print(f"âœ“ ä½œå“: {work_info.name}")
		print(f"âœ“ ç±»å‹: {work_info.type}")
		decompiler_class = self.decompilers.get(work_info.type)
		if not decompiler_class:
			error_msg = f"ä¸æ”¯æŒçš„ä½œå“ç±»å‹: {work_info.type}"
			raise ValueError(error_msg)
		decompiler = decompiler_class(work_info)
		result = decompiler.decompile()
		return self._save_result(result, work_info, output_dir)

	@staticmethod
	def _save_result(result: dict[str, Any] | str, work_info: WorkInfo, output_dir: str) -> str:
		"""ä¿å­˜åç¼–è¯‘ç»“æœ"""
		FileHelper.ensure_dir(output_dir)
		if work_info.is_nemo:
			if isinstance(result, str):
				return result
			msg = "Nemoä½œå“åº”è¯¥è¿”å›å­—ç¬¦ä¸²è·¯å¾„"
			raise TypeError(msg)
		file_name = FileHelper.safe_filename(work_info.name, work_info.id, work_info.file_extension.lstrip("."))
		file_path = Path(output_dir) / file_name
		if isinstance(result, dict):
			FileHelper.write_json(file_path, result)
		else:
			msg = "éNemoä½œå“åº”è¯¥è¿”å›å­—å…¸"
			raise TypeError(msg)
		return str(file_path)


def decompile_work(work_id: int, output_dir: str = "decompiled") -> str:
	"""
	åç¼–è¯‘ä½œå“
	Args:
		work_id: ä½œå“ID
		output_dir: è¾“å‡ºç›®å½•
	Returns:
		ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
	"""
	decompiler = Decompiler()
	return decompiler.decompile(work_id, output_dir)


if __name__ == "__main__":
	work_id = int(input("è¯·è¾“å…¥ä½œå“ID: "))
	output_path = decompile_work(work_id)
	print(f"âœ“ åç¼–è¯‘å®Œæˆ: {output_path}")
